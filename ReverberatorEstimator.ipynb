{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af835bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tfkl\n",
    "import tensorflow_io as tfio\n",
    "import functools\n",
    "from pedalboard import load_plugin\n",
    "from ReverberatorEstimator import layers, loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import os\n",
    "import librosa.display\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9b6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 48000\n",
    "num_params = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7638df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_audio = tfio.audio.AudioIOTensor(\"Dataset/Wet/Snap.wav\")\n",
    "target_audio = target_audio.to_tensor()\n",
    "target_audio = tf.slice(target_audio, begin=[0,0], size=[-1,1])\n",
    "target_audio = tf.cast(target_audio, tf.float32) / 32768.0\n",
    "target_audio = tf.squeeze(target_audio)\n",
    "target_audio = tf.reshape(target_audio,(1, 96000))\n",
    "input_audio = tfio.audio.AudioIOTensor(\"Dataset/Dry/Snap.wav\")\n",
    "input_audio = input_audio.to_tensor()\n",
    "input_audio = tf.slice(input_audio, begin=[0,0], size=[-1,1])\n",
    "input_audio = tf.cast(input_audio, tf.float32) / 32768.0\n",
    "input_audio = tf.squeeze(input_audio)\n",
    "input_audio = tf.reshape(input_audio,(1, 96000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9044266",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.abspath(\"./Dataset\")\n",
    "\n",
    "dry_files = []\n",
    "\n",
    "for f in range(8):\n",
    "    audio = tfio.audio.AudioIOTensor(dataset_path + \"/Dry/Snap.wav\")\n",
    "    audio = audio.to_tensor()\n",
    "    audio = tf.slice(audio, begin=[0,0], size=[-1,1])\n",
    "    audio = tf.cast(audio, tf.float32) / 32768.0\n",
    "    audio = tf.squeeze(audio)\n",
    "    audio = tf.reshape(audio,(96000))\n",
    "    dry_files.append(audio)\n",
    "    \n",
    "x_train = tf.stack(dry_files)\n",
    "\n",
    "wet_files = []\n",
    "\n",
    "for f in range(8):\n",
    "    audio = tfio.audio.AudioIOTensor(dataset_path + \"/Wet/Snap.wav\")\n",
    "    audio = audio.to_tensor()\n",
    "    audio = tf.slice(audio, begin=[0,0], size=[-1,1])\n",
    "    audio = tf.cast(audio, tf.float32) / 32768.0\n",
    "    audio = tf.squeeze(audio)\n",
    "    audio = tf.reshape(audio,(96000))\n",
    "    wet_files.append(audio)\n",
    "    \n",
    "y_train = tf.stack(wet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5126ad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'VST3Plugin' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20744/3469637813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameter_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mvstlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVSTProcessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../Reverberator.vst3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvstlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maudio_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Projects\\SMC\\ReverberatorEstimator\\ReverberatorEstimator\\layers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_to_vst, sample_rate, n_processors, *args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel_Batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_processors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_vst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustom_gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Projects\\SMC\\ReverberatorEstimator\\ReverberatorEstimator\\layers.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m             p = Process(target=Parallel_Batch.pipe, \n\u001b[0;32m    150\u001b[0m                 args=(parent_conn, child_conn, vst, self.sample_rate))\n\u001b[1;32m--> 151\u001b[1;33m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m             \u001b[0mprocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchild_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'VST3Plugin' object"
     ]
    }
   ],
   "source": [
    "logmelgram = layers.LogMelgramLayer(1024, 256, 128, sample_rate, 0.0, sample_rate//2, 1e-6)\n",
    "audio_time = tfkl.Input(shape=(96000,), name=\"audio_time\")\n",
    "\n",
    "x = logmelgram(audio_time)\n",
    "x = tfkl.BatchNormalization(name=\"input_norm\")(x)\n",
    "encoder_model = tfk.applications.MobileNetV2(input_shape=(x.shape[1], x.shape[2], x.shape[3]), alpha=1.0,\n",
    "                                            include_top=True, weights=None, input_tensor=None, pooling=None,\n",
    "                                            classes=np.sum(num_params).item(), classifier_activation=\"sigmoid\")\n",
    "\n",
    "hidden = encoder_model(x)\n",
    "\n",
    "parameter_model = tfk.models.Model(audio_time, hidden, name=\"parameter_model\")\n",
    "\n",
    "parameters = parameter_model(audio_time)\n",
    "\n",
    "vstlayer = layers.VSTProcessor(\"../Reverberator.vst3\", sample_rate)\n",
    "output = vstlayer([audio_time, parameters])\n",
    "\n",
    "model = tfk.models.Model(audio_time, output, name=\"full_model\")\n",
    "\n",
    "spectral_loss = loss.multiScaleSpectralLoss(sr=sample_rate)\n",
    "\n",
    "optimizer = tfk.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=spectral_loss, metrics=['mae'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523328db",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_model.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore from latest checkpoint\n",
    "model.load_weights(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ff530",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pre = (model.call(input_audio)).numpy()[0]\n",
    "old_params = parameter_model(input_audio).numpy()[0]\n",
    "print(old_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cp = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir, \n",
    "                             monitor='loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss',\n",
    "                                  factor=0.2,\n",
    "                                  patience=10,\n",
    "                                  cooldown=0,\n",
    "                                  verbose=1,\n",
    "                                  mode='min',\n",
    "                                  min_lr=0.0000016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18544c22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(x_train, y_train, verbose=1, epochs=10,\n",
    "         callbacks=[model_cp,reduce_lr])\n",
    "print(\"Training took %d seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_audio = model(input_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(7,10))\n",
    "ax[0].plot(audio_pre)\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_pre)), ref=np.max)\n",
    "img = librosa.display.specshow(D, y_axis='linear', x_axis='time',\n",
    "                               sr=sample_rate, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ab5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "ax[0,0].plot(output_audio.numpy()[0])\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(output_audio.numpy()[0])), ref=np.max)\n",
    "img = librosa.display.specshow(D, y_axis='linear', x_axis='time',\n",
    "                               sr=sample_rate, ax=ax[1,0])\n",
    "ax[0,1].plot(target_audio.numpy()[0])\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(target_audio.numpy()[0])), ref=np.max)\n",
    "img = librosa.display.specshow(D, y_axis='linear', x_axis='time',\n",
    "                               sr=sample_rate, ax=ax[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff082009",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(output_audio, rate=sample_rate, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d5ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_pre, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b64e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(target_audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89028e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump values to .csv files\n",
    "np.savetxt(\"output_audio.csv\", output_audio.numpy()[0], delimiter=\",\")\n",
    "np.savetxt(\"target_audio.csv\", target_audio.numpy()[0], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcc679",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = parameter_model(input_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58656f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = parameters.numpy()[0]\n",
    "filter_c = 1\n",
    "for i in range(num_params):\n",
    "    if i < 4:\n",
    "        print(\"b_%i = %f\" % (i, params[i]))\n",
    "    elif i < 8:\n",
    "        print(\"c_%i = %f\" % (i-4, params[i]))\n",
    "    else:\n",
    "        j = (i-8) % 5\n",
    "        \n",
    "        if j is 0:\n",
    "            print(\"\\nFilter %i:\" % filter_c)\n",
    "            filter_c = filter_c + 1\n",
    "            print(\"c_hp = %f\" % params[i])\n",
    "        elif j is 1:\n",
    "            print(\"c_bp = %f\" % params[i])\n",
    "        elif j is 2:\n",
    "            print(\"c_lp = %f\" % params[i])\n",
    "        elif j is 3:\n",
    "            print(\"g = %f\" % params[i])\n",
    "        elif j is 4:\n",
    "            print(\"R = %f\" % params[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_diff = params - old_params\n",
    "print(param_diff)\n",
    "plt.stem(param_diff)\n",
    "plt.ylim([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1770da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad95c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874752c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
